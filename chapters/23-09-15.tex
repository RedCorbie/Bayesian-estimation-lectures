\begin{definition}
	$\delta$-сеть: $$ \theta_1, \ldots, \theta_n: \ \forall \theta \in K \exists k: \ \phi(\theta, \theta_k) < \delta $$
	$$ z_{ij} = |T(\theta, x_i) - \mu(\theta) - T(\theta_0, x_1) - \mu(\theta_0)| \to 0 $$
	$$ \lim_{\substack{\delta \to 0}} \sup_{\substack{\theta: |\theta-\theta_n|< \delta}} |T(\theta, x_1) - \mu(\theta) - T(\theta_0, x_1) - \mu(\theta_0)| \to 0$$
\end{definition}

Перепишем условие теоремы:
$$ |\frac{1}{n} \sumi T(\theta, x_i) - \mu(\theta)| = |\frac{1}{n} \sumi \big( T(\theta, x_i) - \mu(\theta)\big)| = |\frac{1}{n} \sumi \big( T(\theta, x_i) - \mu(\theta) - T(\theta_j, x_i) + \mu(\theta_j)\big) + \frac{1}{n} \sumi T(\theta_j, x_i) - \mu(\theta_j)| \leq$$
$$ \leq |\frac{1}{n} \sumi z_{ij}| + |\frac{1}{n} \sumi T(\theta_j, x_i) - \mu(\theta_j)| $$

Хотим: $|\frac{1}{n} \sumi T(\theta_j, x_i) - \mu(\theta_j)| < \epsilon$ для $n>n(\epsilon)$ \\
$\mu(\theta_j) = T(\theta_j, x_1)$ - матожидание при фиквированном x
$$ \delta > 0: |\frac{1}{n} \sumi z_{ij}| < 2\epsilon $$

\begin{theorem}
	$\Theta$ - компактное метрическое пространство, $\theta_0$ - фиксированное
	$$ T(\theta, X) = \log \frac{\set{P}_{\theta}}{\set{P}_{\theta_0}} $$
	Если выполнены условия 1)-2) из предыдущей теоремы:
	\begin{enumerate}
		\item $MLE \ \valuation$ состоятельна в $\theta_0$
		\item $\frac{\prod_{i=1}^n \set{P}_{\theta}(X_i)}{\int_{\Theta} \prod_{i=1}^n \set{P}_{\theta}(X_i)d\Pi(\theta)}$ состоятельна в $\theta_0$
	\end{enumerate}
\end{theorem}

\subsection*{Условия Вальда}
\begin{enumerate}
	\item $\Theta = \bigcup K_i$, где $K_1 \subset K_2 \subset \ldots$ \\
	$\forall \braces{\theta_i}: \theta_i \in K_{i=1} \bigcap K_i$
	$$ lim_{\substack{i \to \infty}} p(X, \theta_i) = 0 $$

	\item $\Phi_i(X) = \sup_{\substack{\theta \in K_{i-1}}} \log \frac{p(X, \theta)}{p(X, \theta_0)} \Rightarrow \set{E}_{\theta_0} \Phi_i(X_1) < \infty$ для некоторого i
\end{enumerate}
$K_1:$ $$ \lim_{\substack{i \to \infty}} \Phi_i(X) = -\infty $$
$K_2: \lim_{\substack{i \to \infty}} \set{E}_{\theta_0} \Phi_i(X_1) = - \infty$

\begin{remark}
	Состоятельность MLE не всегда идет с состоятельностью априорных вероятностных мер
\end{remark}

\begin{example}[Есть состоятельность MLE, нет состоятельности апр. вер. мер] 
	$\Theta = (0,1) \bigcup (2,3), \ p_{\theta}(X)$ - равномерное распределение на $[0, \theta], \ \theta_0 = 1$
	$$ \pi(\theta) = \begin{cases}
		\exp\braces{-\frac{1}{(\theta-\theta_0)^2}}, & \theta \in (0,1) \\
		непрерывная \ ф-цияб & \theta \in (2,3)
	\end{cases} $$
	При заданной выборке $X_1, \ldots, X_n$ (достаточно числа наблюдений и порядковой статистики $X_{(n)}$)
	$\Rightarrow$ $$ \frac{1}{\theta^n} I_{(0, \theta)}(X_{(n)}) = p(\set{X}_n|\theta) $$
	$$ \prob{\theta \in (2,3)} = \frac{\int_2^3 p(\set{X}_n | \theta) \pi(\theta) d\theta}{\Big( \int_0^1 d\theta + \int_2^3 d\theta \Big)} = \frac{\int_2^3 \frac{1}{\theta^n}\pi(\theta)d\theta}{\int_{X_{(n)}}^1 \frac{1}{\theta^n} \pi(\theta)d\theta + \int_2^3 \frac{1}{\theta^n} \pi(\theta) d\theta} \  (*)$$
	Обозначим: $$ I_1 = \int_{X_{(n)}}^1 \frac{1}{\theta^n} \pi(\theta)d\theta  $$ $$ I_2 =  \int_2^3 \frac{1}{\theta^n} \pi(\theta) d\theta)$$
	$I_1) $
	$$ I_1 \leq \pi(X_{(n)}) \int_{X_{(n)}}^1  \theta^{-n} d\theta = \frac{\pi(X_{(n)}}{n-1} \frac{1-X_{(n)}}{X_{(n)}^{n-1}}$$
	$$ \frac{1}{n} \log I_1 \leq \frac{n-1}{n} \log X_{(n)} - \frac{\log(n-1)}{n} + \frac{1}{n} \log (1-X_{(n)}^{(n-1)}) + \frac{1}{n} \log \pi(X_{(n)}) \to -\infty (n \to \infty) $$

	$$ X_{(n)} = \max X_i $$
	$$ \prob{X_{(n)}< 1-\delta} = (1-\delta)^n $$
	$$ \delta = \frac{1}{n}, \ \frac{1}{2} < \alpha < 1 \ \Rightarrow \ \prob{X_{(n)}< 1-\delta} = (1-\frac{1}{n^\alpha})^n$$
	$I_2)$
	$$\frac{1}{3^n} \pi((2,3)) \leq \int_2^3 \frac{1}{\theta^n} \pi(\theta) d\theta \leq \frac{1}{2^n} \pi((2,3)) $$
	$\Rightarrow$ $$ \frac{I_1}{I_2} \to 0, n \to \infty $$
	$\frac{(*)}{I_2} \to 1 \ \Rightarrow $ в окрестности 1 сосредоточена нулевая мера, на (2,3) - единичная вероятность
	$$ \prob{\set{X}_n|\theta} = \frac{1}{\theta^n} I_{(0, \theta)}(X_{(\theta)}) \pi(\theta) $$
	На $(2,3)\bigcup (0,1): \hat{\theta}_{MLE} = X_{(n)}$\\
	При размере выборки, стремящемся к бесконечности, оценка стремится к правдивому значению параметра
\end{example}

Пусть $\Theta = \braces{1, \ldots, k}$ - конечное пространство параметров. Задать в нем распределение = задать вероятностный k-вектор: $p_1, \ldots, p_k: \sum_{i=1}^k p_i = 1 \Leftrightarrow p_1, \ldots, p_{k-1}, 1-\sum_{i=1}^{k-1}$

\begin{example}[Распределение Дирихле]
$$ \prod (p_1, \ldots, p_{k-1}) = \frac{\Gamma(\sum_{i=1}^k \alpha_i)}{\prod_{i=1}^k \Gamma(\alpha_I)} p_1^{\alpha_1-1}  \ldots p_{k-1}^{\alpha_{k-1}-1} \Big( 1- \sum_{i=1}^{k-1} p_i\Big)^{\alpha_k -1} $$
$$ \Gamma(z) = \int_0^{\infty} t^{z-1} e^{-t} dt, \ Re(z) > 0 $$
\end{example}

\begin{theorem}[де Финетти]
	Последовательность случайных величин $x_1, \ldots, x_n$ - перестановочна $\Leftrightarrow \ p(x_1, \ldots, x_n) = \int_{\Theta} \prod_{i=1}^n p(x_i|\theta)dP(\theta) \forall n$ - конечное
\end{theorem}

\begin{example}[урна с шарами]
k типов шаров, $\alpha_i$ - шаров i-го типа.
$\alpha_1, \ldots, \alpha_k:$ $$ \prob{X_2=j|X_1=i} = \frac{\alpha_j + \delta_i(j)}{\sum_{m=1}^k \alpha_m + 1} $$
\end{example}

\subsection*{Методы генерации случайных величин из распределений}
\begin{enumerate}
	\item Из функции распределения: $F_X(x), u \sim U[0,1] \Rightarrow X = F_X^{-1}(u)$
	\item $ x = f(Y), \ p_Y(y)\Rightarrow$ \\
	$$ F_Y(y), \ p_Y(y) = \frac{\partial F_Y(y)}{\partial y}, p_X(x) = \frac{\partial F_X(x)}{\partial x} $$
	$$ \Rightarrow p_X(x)= \frac{\partial F_X(x)}{\partial y} \frac{\partial y}{\partial x} = \frac{\partial F_X(x(y))}{\partial y} \frac{\partial y}{\partial x} \circled{=} $$
	$$ F_X(x(y)) = \prob{X<x} = \prob{X<x(y)} = \prob{f^{-1}(x)<y} = \prob{Y<y} = \begin{cases}
		F_Y(y), & монотонно \ возрастает \\
		1 - F_Y(y), & монотонно \ убывает
	\end{cases} $$
	$$ \circled{=}p_Y(y) sign(f(y)) \frac{1}{f'(y)} = p_Y(y) \frac{1}{|f'(y)|} $$
	\item Box-Bekchen \\
	Круг, вписанный в квадрат с углами в (-1,-1) и (1,1). Кидаем в квардарт точку с координатами $(x_1, x_2)$. Если точка вне круга - выкидываем. Внутри круга - «растягивает» вероятностную меру из каждой точки на луч: $$ y_i = x_i \big( \frac{-2\ln x_i}{r^2}\big)^{\frac{1}{2}} $$
	\item $N(\bar{0}, I_q)$ - генерировать из него $N(\bar{m}, \Sigma)$ \\
	Линейные преобразования: $y=AX+b, \ A \in Mat(q,q), b \in \setR^q$
	$$ \set{E}Y = b $$
	$$ \ex{(Y-b)(Y-b)^T} = \ex{AXX^TA^T} = A \ex{XX^T} A^T = AA^T (из \ предположения \ о \set{E}X)$$
	$ \Rightarrow \ Y = LX + \bar{m} $, где $L:LL^T=\Sigma (\Sigma= U \Lambda U^T - SVD \Rightarrow L=U\Lambda^{1/2} \ или \ L=U \Lambda^{1/2}Q, где \ Q \ ортогональная \ или \ LL^T = LL = \Sigma)$
	\item Методы Монте Карло: метод выборки с отклонением
	\begin{itemize}
		\item умеет считать $\prob{X}$
		\item умеем считать $q(x)$
		\item умеем генерировать $Y \subset q(x)$
		\item надо: $z \subset p(x)$
	\end{itemize}

	$$ k: \forall x \in \set{X} \ kq(x) \geq p(x) $$
	\begin{enumerate}
		\item $x_1 \subset q(x)$
		\item если $u \sim U[0,1]$ и $u < \frac{p(x_1)}{kq(x_1)}$ - принимаем $x_1$, иначе к шагу 1
	\end{enumerate}
	$$ \prob{[x, x+dx]} \approx q(x)dx \frac{\prob{x}}{kq(x)} = \frac{\prob{x}dx}{k}$$
	$$ \breve{\prob{x}} \sim \frac{\prob{x}}{k} $$
	$\Rightarrow$
	$$ \breve{\prob{x}} = \frac{\prob{x}}{k} \frac{1}{\int_\set{X} \frac{\prob{X}}{k} dx} = \prob{x}$$
	$$ \prob{принятие \ с. \ в.} = \int-{\set{X}} \prob{x_1} \frac{1}{kq(x_1)} q(x_1) dx_1 = \frac{1}{k} \int_{\set{X}} \prob{x_1} dx_1 = \frac{1}{k} $$
\end{enumerate}
