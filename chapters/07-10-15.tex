\subsection*{Методы Монте-Карло}
Основаны на двух принципах: марковских сетях и Монте-Карло

\subsection*{Марковские цепи}
\begin{definition}
$ \braces{X_n}_{n \geq 1} $ - марковская цепь $\Leftrightarrow \ \prob{X_n|X_1, \ldots, x_{n-1}} = \prob{X_n|X_{n-1}}$ \\
Задать марковскую цепь - значит, задать \begin{itemize}
	\item $\prob{X_0}$
	\item $T(X_{(m)}, X_{(m+1)}) = \prob{X_{(m+1)}|X_{(m)}}$. Обычно рассматривают однородные марковские цепи, когда такая вер-ть зависит только от наблюдения, а не номера шага
\end{itemize}
На следующем шаге можем записать: $$ \prob{X_{(m+1)}} = \sum_{X_{(m)}} \prob{X_{(m)}} T(X_{(m)}, X_{(m+1)})$$
\end{definition}
\begin{definition}
	Распределение $\pi$ стационарное, если выполнено: $$ \pi(X') = \sum_X \pi(X) \prob{X'|X} $$
\end{definition}
\begin{theorem}[Достаточное условие стационарности (детальное расновесие)]
	$$ \pi(X)T(X, X') = \pi(X')T(X',X)  \ \forall X, X'$$
	\begin{proof}
		$$ \sum_X \pi(x) \prob{X'|X} = \sum_X \pi(X')\prob{X|X'} = \pi(X') \sum_X \prob{X|X'} = \pi(X') $$
	\end{proof}
\end{theorem}

\begin{example}[Условие достаточное, но не необходимое]

	\begin{tabular}{lrrrr}
		{} & A & B & C \\
		A & $\frac{1}{2}$ & $\frac{1}{2}$ & 0 \\
		B & 0 & 0 & 1 \\
		C & 1 & 0 & 0
	\end{tabular}
	$$ \pi = \begin{pmatrix}
		\frac{1}{2} \\ \\
		\frac{1}{4} \\ \\
		\frac{1}{4} \\
	\end{pmatrix}$$ - стационарное распределение.
\end{example}

\begin{definition}
	Марковская цепь называется эргодичной, если $$ \set{P}_{(m)}\braces{X} \underset{m \to \infty}{\to} \pi(X) $$
	Или, что то же самое $ \set{P}^m \to A $: у А все строчки равны
\end{definition}

\begin{definition}
	Марковская цепь регулярна, если она состоит из одного циклического класса (состояния нельзя разбить на одно подмножество так, чтобы стартуя из одного можно было прийти в другое)
\end{definition}

\begin{remark}
	Регулярность $\Leftrightarrow \ \exists m : \set{P}^m$ не имеет нулей
\end{remark}

\begin{lem}
	$ P \in Mat(r\times r), \epsilon $ - ее минимальный элемент, $P$ - вероятностная. $X \in Mat(r \times 1), m_0$ - минимальный элемент, $M_0$ - максимальный элемент. Обозначим $M_1, m_1$ - максимум и минимум для $PX$. Тогда
	\begin{itemize}
		\item $M_1 \leq M_0$
		\item $m_1 \geq m_0$
		\item $M_1 - m_1 \leq (1-2\epsilon)(M_0-m_0)$
	\end{itemize}

	\begin{proof}
		Заменим $X$ на $X'$ такое, что у негов се элементы, кроме одного, равны $M_0$, а один равен $m_0$. Тогда $X' \geq X$ и если $a$ - элемент $P$, который домножается на $m_0$:
		$$ P_{(l)}X' = a m_0 + (1-a) M_0 = M_0 - a(M_0-m_0)$$
		$$ M_1 \leq M_0 - a(M_0-m_0) \leq M_0 - \epsilon(M_0-m_0)$$
		Продолжая рассуждения аналогично: $$ -m_1 \leq -m_0 - \epsilon(m_0-M_0) $$
		Складывая, поучаем искомое
	\end{proof}
\end{lem}

\begin{theorem}
	Регулярные марковские цепи эргодичны \\
	\begin{proof}
		Так как цепь регулярна, то $\exists m: P^m$ без нулевых элементов, и все элементы $\geq \epsilon$. 
		$ e_j = (\delta_{ij}) $ - элемент базиса \\
		$$ P^n e_j = P^{n(1-[\frac{n}{m}]n)}(P^m)^{[\frac{n}{m}]} e_j$$
		Выполнены условия леммы, разность между максимальным и минимальным элементами этого вектора мажорируется $$ (1-2\epsilon)^{[\frac{n}{m}]} \underset{n \to \infty}{\to} $$
		$\Rightarrow$ $$ P^n I \underset{n \to \infty}{\to} A $$
	\end{proof}
\end{theorem}

\begin{example}[Марковская цепь с бесконечным числом состояний]
Пусть множество состояний: $\setR$, начальное состояние $Z_0=0$, а переходная матрица: 
$$ \prob{Z_{(m+1)} = Z_{(m)} + 1|Z_{(m)}} = \frac{1}{4} $$
$$ \prob{Z_{(m+1)} = Z_{(m)} - 1|Z_{(m)}} = \frac{1}{4} $$
$$ \prob{Z_{(m+1)} = Z_{(m)}|Z_{(m)}} = \frac{1}{2} $$
Tак как матрица переходов симметрична и по сути имеем случайное блуждание:
$$\ex{Z_{(m)}} = 0$$ 
Смещение: $\xi_k = Z_{(k)}-Z_{(k-1)}$
$$ \ex{Z_{(m)}^2} = \ex{\sum_{k=1}^m \xi_k^2} = m \ex{\xi_1^2} = \frac{m}{2} $$
$\Rightarrow \set{D}\braces{Z_{(m)}} \sim \sqrt{m}$
\end{example}

\subsection*{Алгоритмы сэмплирования}
\subsubsection*{Metropolis(1953)}
Постановка задачи: Научиться в пределе генерировать с.в. из заданного распределения (умеем считать ненормированную плотность) $$ \check{p}(x): \prob{X} = \frac{\check{p}(x)}{Z_p} $$
$q(X|X^{(\tau)}): q$ - симметрично: $q(X|X') = q(X'|X)$ \\

Алгоритм: \begin{enumerate}
	\item $x^{(0)} = X_0$
	\item $A(x^*, x^{(\tau)}) = \min \big( 1, \frac{\prob{x*}}{\prob{x^{(\tau)}}}\big)$
	\begin{enumerate}
		\item Генерируем $x^*$ из $q(z|z^{(\tau)}$
		\item $x^{(\tau+1)} = x^*$ с вероятнотью $A(x^*, x^{(\tau)}), \ x^{(\tau+1)} = x^{(\tau)}$ иначе
	\end{enumerate}
\end{enumerate}

Из теоремы об эргодичности регулярных МЦ, получаем, что у такого распределения предельное рапределение есть


\subsubsection*{Metropolis-Hastings (1970)}
Условия аналогичные: $\check{p}, q(x|x^{(\tau)}), $ но q не симметрично.
Алгоритм аналогичный, но по-другому определяем $A(x^*, x^{(\tau)})$:
$$ A(x^*, x^{(\tau)}) = \min \big( 1, \frac{\check{p}(x^*) q(x^{(\tau)}|x^*)}{\check{p}(x^{(\tau)}) q(x^*|x^{(\tau)})}\big) $$

Из теоремы об эргодичности регулярных МЦ, получаем, что у такого распределения предельное рапределение есть

$$ p(x) q(x|x')A(x',x) = \min(p(x)q(x|x'), p(x')q(x'|x)) = p(x')q(x'|x) \min(1, p(x)q(x,x')) = p(x')q(x,x')A(x,x') $$


\subsubsection*{Сэмплирование Гиббса(1984)}
Хотим сгенерировать посл-ть из ровно $m$ элементов из некоторого распределения $p(Z) = p(Z_1, \ldots, Z_m$. Умеем для любого $i \prob{Z_i|\set{Z}_{-i}}$ генерировать точку, если есть все распределение, кроме точки i.
\begin{enumerate}
	\item Имеем $Z_1^{(\tau)}, \ldots, Z_m^{(\tau)}$
			$$ Z_1^{(\tau+1)} \sim \prob{Z_1|Z_2^{(\tau)}, \ldots, Z_M^{(\tau)}} $$
			$$ Z_2^{(\tau+1)} \sim \prob{Z_2|Z_1^{(\tau)}, \ldots, Z_M^{(\tau)}} $$
			$$ \ldots $$
			$$ Z_M^{(\tau+1)} \sim \prob{Z_M|Z_1^{(\tau)}, \ldots, Z_{M-1}^{(\tau)}} $$
\end{enumerate}
 Для аналогии с Метрополисом-Хастингом: $q_k(Z^*|Z) = \prob{Z_k^*|\set{Z}_{-k}}$. Покажем, что правило вырождается в тривиальное: 
 $$ A(Z^*, Z) = \frac{p(z^*)q_k(z|Z^*)}{p(z)q_k(z^*|z)} = \frac{ \prob{z^*|\set{Z}_{k-1}^*}\prob{\set{Z}_{-k}^*} \prob{Z_k|\set{Z}_{-k}^*} }{  \prob{z_k|\set{Z}_{k-1}^*}\prob{\set{Z}_{-k}^*} \prob{Z^*|\set{Z}_{-k}^*}  } $$

\begin{remark}
Сложность генерации в этом методе напрямую зависит от сложности генерации $p(Z_k|\set{Z}_{-k})$. Поэтому рассматривают блочные модификации, когда блок переменных зависит не от всех переменных, а только от какогото подблока, для упрощения генерации.
\end{remark}

\begin{remark}
	Эти методы очень удобны в графических моделях, где часто значение $Z_k$ зависит только от своих родителей.
\end{remark}

\begin{remark}
	$$ p(x,y) \propto \exp (-x^2y^2) $$
	$$ Z^{(\tau)} \mapsto Z'^{(\tau)} $$
	$$ Z'^{(\tau)} = \mu_i + \alpha(z^{(\tau)} - \mu^{(\tau)}) + \sigma^{(\tau)}(1-\alpha^2)^{\frac{1}{2}} \nu \sim N(0,I), \ -1<\alpha<1  $$
\end{remark}